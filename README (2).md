
# Syst√®me Unifi√© de D√©tection de Menaces (Spark Streaming)

> D√©tection en temps r√©el des attaques Web, tentatives de brute-force et fraude par **carding** √† l'aide d'**Apache Spark Structured Streaming**, **Kafka**, **Elasticsearch** et **Kibana**.

---

## üóÇÔ∏è Table des mati√®res
- [Pr√©sentation](#pr√©sentation)
- [Architecture](#architecture)
- [Fonctionnalit√©s cl√©s](#fonctionnalit√©s-cl√©s)
- [Pr√©requis](#pr√©requis)
- [D√©marrage rapide](#d√©marrage-rapide)
- [Lancement du Job Spark](#lancement-du-job-spark)
- [Simulation d'attaques](#simulation-dattaques)
- [Logique de d√©tection](#logique-de-d√©tection)
- [Sch√©ma des donn√©es](#sch√©ma-des-donn√©es)
- [Tableaux de bord & Visualisation](#tableaux-de-bord--visualisation)
- [Param√©trage & Personnalisation](#param√©trage--personnalisation)
- [D√©pannage](#d√©pannage)
- [S√©curit√© & Bonnes pratiques](#s√©curit√©--bonnes-pratiques)
- [Roadmap](#roadmap)
- [Licence](#licence)

---

## Pr√©sentation
Ce projet impl√©mente une **solution de d√©tection unifi√©e** des menaces en temps r√©el. Il utilise une approche **hybride** combinant :
- **Signatures** (regex pour Web/XSS/SQLi/LFI/RFI/RCE/Brute-Force),
- **Threat Intelligence (TI)** (IP/UA blacklists diffus√©es en broadcast),
- **Heuristiques d'anomalie** (Entropie & Ratio de caract√®res sp√©ciaux) pour rep√©rer obfuscation et exfiltration.

Le pipeline lit des messages **Kafka** (`syslogs`, `fraud_alerts`), enrichit les √©v√©nements, applique les r√®gles, et **indexe** les alertes pertinentes dans **Elasticsearch** pour visualisation via **Kibana**.

---

## Architecture
L'infrastructure est orchestr√©e via **Docker Compose**.

```
+------------------+       +------------------+       +---------------------+       +------------------+
|  Syslog-ng/Apps  |  -->  |  Kafka+Zookeeper |  -->  |  Spark (Streaming)  |  -->  |  Elasticsearch   |
| (Logs & Events)  |       |  Ingestion Bus   |       |  D√©tection & Enrich |       |  Index & Search  |
+------------------+       +------------------+       +---------------------+       +------------------+
                                                                    |                         |
                                                                    +-------------------------+
                                                                    |     Kibana (Dashboards) |
                                                                    +-------------------------+
```

**Composants**
- **Ingestion** : Kafka, Zookeeper, Syslog-ng
- **Traitement** : Spark Master/Workers (PySpark)
- **Stockage/Indexation** : Elasticsearch
- **Visualisation** : Kibana

---

## Fonctionnalit√©s cl√©s
- Lecture **en continu** depuis Kafka.
- **Feature Engineering** : entropie, ratio de caract√®res sp√©ciaux, extraction IP/UA.
- **R√®gles de signatures** pour les attaques Web, brute-force, reverse shell, CVE (Log4Shell), etc.
- **D√©tection IA heuristique** : obfuscation (Base64), exfiltration, injection de code.
- **Enrichissement GeoIP** via pipeline d'ingestion Elasticsearch.
- **Alerting** : index `security_events` aliment√© en temps r√©el.

---

## Pr√©requis
- **Docker** & **Docker Compose** install√©s.
- Environnement de travail : Windows, Linux, ou macOS.
- Acc√®s r√©seau local pour les conteneurs (bridge `fraud-net`).

---

## D√©marrage rapide
1. **Cloner le d√©p√¥t** ou copier les fichiers dans un r√©pertoire.
2. **D√©marrer l'infrastructure** :
   ```bash
   docker-compose up -d
   ```
3. **V√©rifier les services** :
   - Kafka/Zookeeper d√©marr√©s,
   - Elasticsearch & Kibana accessibles,
   - Spark Master/Workers en ligne.

**Acc√®s UI**
- Kibana : http://localhost:5601
- Spark UI : http://localhost:8080

---
## üöÄ Installation et Mise en Place

### ‚úÖ Pr√©requis
- Docker Desktop
- Git
- Windows PowerShell

### üõ†Ô∏è √âtapes
#### 1) Cloner le projet
```bash
git clone https://github.com/BALLEGI/realtime-fraud-detection1
cd realtime-fraud-detection1
```

#### 2) D√©marrer l'infrastructure
```bash
docker-compose up -d
```
‚è≥ Attendre ~60s pour l'initialisation compl√®te.

#### 3) Configurer Elasticsearch
Acc√©dez √† Kibana : [http://localhost:5601](http://localhost:5601)

Allez dans **Dev Tools** et ex√©cutez :

**Pipeline GeoIP**
```json
PUT /_ingest/pipeline/geoip-enrichment
{
  "description": "GeoIP enrichment for SIEM",
  "processors": [
    {
      "geoip": {
        "field": "source_ip",
        "target_field": "geoip",
        "ignore_failure": true
      }
    }
  ]
}
```

**Template d'Index**
```json
PUT _index_template/security_template
{
  "index_patterns": ["security_events*"],
  "template": {
    "mappings": {
      "properties": {
        "@timestamp": { "type": "date" },
        "geoip": { "properties": { "location": { "type": "geo_point" } } },
        "source_ip": { "type": "ip" },
        "attack_type": { "type": "keyword" },
        "transaction": { "properties": { "amount": { "type": "double" } } }
      }
    }
  }
}
```

#### 4) Cr√©er les Topics Kafka (Optionnel)
```bash
docker exec kafka kafka-topics --create --topic syslogs --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
docker exec kafka kafka-topics --create --topic fraud_alerts --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1
```

#### 5) Importer le Dashboard Kibana
- Allez dans **Kibana ‚Üí Stack Management ‚Üí Saved Objects ‚Üí Import**.
- Importez le fichier `dashboard.ndjson` fourni.

---

## üéÆ Utilisation

### ‚ñ∂Ô∏è Lancer le moteur de d√©tection
```powershell
start-detection.bat
```
‚úÖ Attendez le message : `Pipeline Unifi√© Actif. √âcriture vers 'security_events'...`

### üß™ Simuler des attaques
- **Fen√™tre 1 : Fraude bancaire**
```powershell
.\generate-carding-attack.ps1
```
- **Fen√™tre 2 : Attaques Web**
```powershell
.\generate-web-attacks.ps1
```
- **Fen√™tre 3 : Brute Force SSH**
```powershell
.\generate-attack.ps1
```

### üîç Observer en temps r√©el
- Kibana ‚Üí Dashboard **Unified Security Center**.
- P√©riode : `Today` ou `Last 1 hour`.
## Lancement du Job Spark
Le script de d√©tection **`spark_fraud_detection.py`** doit √™tre soumis au cluster Spark.

> Les packages n√©cessaires (connecteurs) sont r√©solus via Ivy au premier lancement.

### Windows
Utilisez le script fourni :
```bat
start-detection.bat
```

### Linux/macOS
Ex√©cutez les commandes suivantes :
```bash
# 1) Copier le script dans le conteneur spark-master
docker cp spark_fraud_detection.py spark-master:/opt/spark/spark_fraud_detection.py

# 2) Pr√©parer les permissions Ivy (cache JAR)
docker exec -u 0 spark-master bash -c "mkdir -p /home/spark/.ivy2/cache /home/spark/.ivy2/jars && chown -R spark:spark /home/spark/.ivy2"

# 3) Lancer le job Spark (mode client)
docker exec -it --user spark spark-master /opt/spark/bin/spark-submit \
  --master spark://172.25.0.10:7077 \
  --deploy-mode client \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.3,org.elasticsearch:elasticsearch-spark-30_2.12:8.15.2 \
  /opt/spark/spark_fraud_detection.py
```

> **Note** : Adaptez les versions des packages au runtime Spark/Scala et √† la version d'Elasticsearch du projet.

---

## Simulation d'attaques
Des scripts **PowerShell (`.ps1`)** permettent d'injecter des √©v√©nements de test dans Kafka pour valider la d√©tection :
- `generate-attack.ps1` : brute-force SSH (Linux/Windows).
- `generate-web-attacks.ps1` : SQLi (`UNION SELECT`, `' OR '1'='1'`), XSS (`<script>`), LFI (`../`).
- `generate-carding-attack.ps1` : transactions de **carding** g√©o-dispers√©es.

> Les alertes apparaissent en temps r√©el dans **Kibana** une fois le job Spark actif.

---

## Logique de d√©tection
Le fichier **`spark_fraud_detection.py`** impl√©mente :

### 1) Ingestion
- Lecture streaming des topics Kafka : `syslogs` et `fraud_alerts`.

### 2) Feature Engineering
- **Entropie** : rep√®re obfuscation/payloads compress√©s (seuil typique > 4.5).
- **Ratio de caract√®res sp√©ciaux** : d√©tecte injections/commandes (seuil typique > 0.3).
- **Threat Intel** : IP/UA blacklist√©s via fichier JSON diffus√© en **broadcast**.
- **Extraction IP & UA** : depuis payload ou JSON (selon `topic`).

### 3) R√®gles de signatures
- **Brute-Force** : `EventID 4625` (Windows), `Failed password` (Linux/SSH).
- **Attaques Web** : `UNION SELECT`, `' OR '1'='1'` (SQLi), `<script>` (XSS), `../`, `%2e%2e`, `/etc/passwd` (LFI/Traversal), `php://` (RFI).
- **RCE & Reverse Shell** : `system(`, `exec(`, `shell_exec(`, `eval(`), `/bin/sh`, `cmd.exe`, `powershell -enc`, `nc -e`, `ncat`, `/dev/tcp/`.
- **CVE connues** : Log4Shell (`jndi:ldap`, `CVE-2021-44228`), **Shellshock** (regex correctement √©chapp√©e : `\(\) \{ :; \};`).
- **Scanners** : `nmap`, `masscan`, `dirsearch`, `nikto`.

### 4) Heuristiques IA
- `AI_HIGH_ENTROPY_ANOMALY` : entropie √©lev√©e & taille de payload.
- `AI_CODE_INJECTION_ANOMALY` : ratio de sp√©ciaux √©lev√© & longueur.
- `AI_DATA_EXFILTRATION` : longueur > 2000.
- `AI_BASE64_OBFUSCATION` : motifs Base64 longs.

### 5) D√©cision finale
Priorit√©:
1. `CARDING_FRAUD` si `topic == fraud_alerts`.
2. `THREAT_INTEL_BLACKLIST` si IP/UA correspond √† la blacklist.
3. Signature connue (regex).
4. Verdict IA.
5. Sinon `NORMAL_TRAFFIC`.

### 6) Sortie & Filtrage
- √âcriture des alertes (non `NORMAL_TRAFFIC`) vers l'index **`security_events`** d'Elasticsearch.
- Filtre anti-bruit pour certains logs Windows (Auditing).

---

## Sch√©ma des donn√©es
### `fraud_alerts` (JSON attendu)
```json
{
  "transaction_id": "abc-123",
  "amount": 199.99,
  "currency": "EUR",
  "country": "FR",
  "city": "Paris",
  "ip": "198.51.100.23",
  "user": "john.doe",
  "status": "pending",
  "geoip": { "location": "48.8566,2.3522" }
}
```

### Sortie (index `security_events`)
```json
{
  "@timestamp": "2025-11-04T12:34:56Z",
  "attack_type": "SQLI_UNION",
  "entropy": 5.12,
  "special_ratio": 0.41,
  "log_len": 854,
  "source_ip": "203.0.113.45",
  "user": "system_watcher",
  "geoip": { "location": "...", "country_name": "...", "city_name": "..." },
  "transaction": { "amount": 0, "currency": "", "id": "" },
  "raw_message": "..."
}
```

---

## Tableaux de bord & Visualisation
- Cr√©ez un **index pattern** `security_events*` dans Kibana.
- Dashboards recommand√©s :
  - R√©partition des `attack_type` dans le temps,
  - Top `source_ip` par type d'attaque,
  - Cartographie GeoIP,
  - Heatmap entropie/ratio.

---

## Param√©trage & Personnalisation
- **Fichier TI** : `/mnt/data/threat_intel_blacklist.json`
  ```json
  { "ips": ["198.51.100.23"], "user_agents": ["sqlmap", "masscan", "curl/7.", "python-requests"] }
  ```
- **Seuils** : ajuster (entropie, ratio, longueur) selon vos donn√©es.
- **R√®gles** : ajouter/modifier des regex pour votre contexte applicatif.
- **Connecteurs** : adapter versions des packages `spark-sql-kafka` et `elasticsearch-spark`.

---

## D√©pannage
- **Le job ne d√©marre pas** : v√©rifier Spark Master (`http://localhost:8080`), packages r√©solus (cache Ivy).
- **Pas d'√©v√©nements** : confirmer que Kafka re√ßoit des messages (`syslogs`, `fraud_alerts`).
- **Pas d'indexation** : valider la sant√© d'Elasticsearch (`/_cluster/health`) et droits r√©seau.
- **Regex trop agressives** : r√©duire la port√©e pour limiter les faux positifs.
- **M√©moire** : ajuster ressources Docker (RAM/CPU) pour Spark & ES.

---

## S√©curit√© & Bonnes pratiques
- Isoler les **r√©seaux Docker** et limiter l'exposition des ports.
- Mettre √† jour r√©guli√®rement les **blacklists** (TI) et les d√©pendances.
- Journaliser et tracer les d√©cisions (inf√©rence IA vs signature/menace connue).
- Ajouter des **alertes** (Watchers/Alerts Kibana) pour les types critiques (RCE, exfiltration).

---

## Roadmap
- Param√®tres via variables d'environnement (seuils, topics, index).
- Rechargement dynamique du fichier TI.
- Int√©gration **Prometheus/Grafana** pour m√©triques Spark.
- Ajout de **tests unitaires** des UDF.
- Support de **schema registry** et formats Avro/Protobuf.

---

## Licence
Ce projet est publi√© sous licence **MIT** (√† adapter selon vos besoins).

